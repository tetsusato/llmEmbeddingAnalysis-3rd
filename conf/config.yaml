#label: "llama3-JSIAM2024"
#label: "sentence-transformers-JSIAM2024"
label: "mistral-JSIAM2024"

defaults:
    #- io: sentence-transformers
    #- io: mpnet
    #- io: qwen2
    - io: mistral
    #- io: nv-embed
    #- io: llama3
    #- io: llama3-70B
    #- io: reflection-llama-31-70B

# global configuration
hydra:
    run:
#        dir: ./outputs/${hydra.job.name}/${now:%Y-%m-%d_%H-%M}
        dir: /home/tetsu_sato/llmEmbeddingAnalysis-3rd/outputs/tese
    runtime:
        output_dir: /home/tetsu_sato/llmEmbeddingAnalysis-3rd/outputs-dir
    job:
        chdir: True

cache:
    enable: True
    reset: True
    top_dir: "CacheStorage"
    root: "defaultCache"
    pd:
        prefix: "PersistenceDiagram"
        filename: "pd_test01"

# 実験全体のパラメータを書く
execute:
    model_list: ["qwen2", "sentence-transformers", "mistral", "nv-embed", "llama3"]
    data_reset: True # Optunaのクリア
    debug:
        enable: True
        # 全埋め込みベクトルのうち，どこから使うか
        # obsolete
        #start_index: 0
        # 相関係数を計算するのに何個のベクトルを使うか
        # obslete
        #num_inputs: 5
    # 全データのうち，どこから実験に使うか
    start_index: 0
    # 全データのうち，いくつを実験に使うか
    limit: 100
    # 一つの相関係数計算に，何個のベクトルを使うか
    group_num: 5
    multiprocessing_pools: 20
    # optunaのトライアル数
    n_trials: 50
    # 全埋め込みベクトルのうち，start_index以降何個使うか
    # obsolete
    #max_num_inputs: 5
    # ハイパーパラメータ最適化の際，どこまでstart_indexをずらすか
    # obsolete
    #max_start_index: 95
    #max_start_index: 3
    # ハイパーパラメータ最適化の際のステップ幅
    # 通常は? group_numに等しい
    start_index_step: 5

hyper_parameter:
    tda:
        time_delay_low: 1
        time_delay_high: 60
        time_delay_step: 2
        stride_low: 1
        stride_high: 5
        stride_step: 1
        n_low: 20
        n_high: 20
        n_step: 5
        dth: 1
        #embedding_methods: ["reduce_vector_sampling"]
        embedding_methods: ["reduce_vector_takensembedding"]
    tsne:
        perplexity_low: 1
        perplexity_high: 5
        embedding_methods: ["reduce_vector_takensembedding"]